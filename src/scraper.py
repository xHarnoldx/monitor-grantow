# scraper.py - GÅ‚Ã³wny plik agenta monitorujÄ…cego granty

import requests
from bs4 import BeautifulSoup
import time
from datetime import datetime
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
import os

# Konfiguracja email
EMAIL_ADDRESS = os.environ.get('EMAIL_ADDRESS')
EMAIL_PASSWORD = os.environ.get('EMAIL_PASSWORD')
RECIPIENT_EMAIL = os.environ.get('RECIPIENT_EMAIL')

# Strony do monitorowania
WEBSITES_TO_MONITOR = [
    {
        'name': 'Narodowe Centrum Kultury',
        'url': 'https://nck.pl/dotacje-i-stypendia',
        'keywords': ['dziedzictwo', 'digitalizacja', 'archiwum', 'warszawa', 'mazowsze']
    },
    {
        'name': 'Ministerstwo Kultury',
        'url': 'https://www.gov.pl/web/kultura',
        'keywords': ['kultura cyfrowa', 'dziedzictwo', 'edukacja']
    },
    {
        'name': 'Narodowy Instytut Dziedzictwa',
        'url': 'https://nid.pl/pl/',
        'keywords': ['dziedzictwo kulturowe', 'ochrona', 'dokumentacja']
    }
]

# SÅ‚owa kluczowe dla filtrowania
GRANT_KEYWORDS = [
    'dziedzictwo kulturowe',
    'digitalizacja',
    'archiwum cyfrowe',
    'historia mÃ³wiona',
    'edukacja kulturalna',
    'warszawa',
    'mazowsze',
    'ngo',
    'organizacje pozarzÄ…dowe',
    'granty',
    'dotacje',
    'konkurs',
    'nabÃ³r'
]

def send_email(subject, content):
    """WysyÅ‚a email z informacjami o grantach"""
    try:
        # Tworzenie wiadomoÅ›ci
        message = MIMEMultipart()
        message["From"] = EMAIL_ADDRESS
        message["To"] = RECIPIENT_EMAIL
        message["Subject"] = subject
        
        # Dodanie treÅ›ci HTML
        html_content = f"""
        <html>
        <body>
            <h2>ğŸ¯ Nowe moÅ¼liwoÅ›ci grantowe dla Twojej fundacji</h2>
            {content}
            <hr>
            <p><small>Automatyczne powiadomienie wysÅ‚ane przez agenta monitorujÄ…cego granty<br>
            Data: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</small></p>
        </body>
        </html>
        """
        
        message.attach(MIMEText(html_content, "html"))
        
        # WysÅ‚anie emaila
        with smtplib.SMTP("smtp.gmail.com", 587) as server:
            server.starttls()
            server.login(EMAIL_ADDRESS, EMAIL_PASSWORD)
            server.send_message(message)
            
        print("âœ… Email wysÅ‚any pomyÅ›lnie!")
        return True
        
    except Exception as e:
        print(f"âŒ BÅ‚Ä…d wysyÅ‚ania emaila: {e}")
        return False

def check_for_keywords(text, keywords):
    """Sprawdza czy tekst zawiera sÅ‚owa kluczowe"""
    if not text:
        return False
    text_lower = text.lower()
    return any(keyword.lower() in text_lower for keyword in keywords)

def scrape_website(website_info):
    """Sprawdza jednÄ… stronÄ™ pod kÄ…tem nowych grantÃ³w"""
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        
        print(f"ğŸ” Sprawdzam: {website_info['url']}")
        response = requests.get(website_info['url'], headers=headers, timeout=15)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # Szukanie linkÃ³w i tekstÃ³w zawierajÄ…cych sÅ‚owa kluczowe
        found_grants = []
        
        # Sprawdzanie linkÃ³w
        for link in soup.find_all('a', href=True):
            link_text = link.get_text(strip=True)
            if len(link_text) > 10:  # Ignoruj bardzo krÃ³tkie linki
                if (check_for_keywords(link_text, website_info['keywords']) or 
                    check_for_keywords(link_text, GRANT_KEYWORDS)):
                    
                    href = link.get('href')
                    if href.startswith('/'):
                        # WzglÄ™dny URL - dodaj domenÄ™
                        base_url = f"https://{website_info['url'].split('/')[2]}"
                        href = base_url + href
                    elif not href.startswith('http'):
                        href = website_info['url'] + '/' + href
                    
                    found_grants.append({
                        'title': link_text[:150],  # Ograniczenie dÅ‚ugoÅ›ci
                        'url': href,
                        'type': 'link',
                        'source': website_info['name']
                    })
        
        # Sprawdzanie nagÅ‚Ã³wkÃ³w
        for header in soup.find_all(['h1', 'h2', 'h3', 'h4']):
            header_text = header.get_text(strip=True)
            if len(header_text) > 10:
                if (check_for_keywords(header_text, website_info['keywords']) or 
                    check_for_keywords(header_text, GRANT_KEYWORDS)):
                    found_grants.append({
                        'title': header_text[:150],
                        'url': website_info['url'],
                        'type': 'header',
                        'source': website_info['name']
                    })
        
        # Sprawdzanie paragrafÃ³w (ograniczone)
        for paragraph in soup.find_all('p')[:20]:  # Tylko pierwsze 20 paragrafÃ³w
            paragraph_text = paragraph.get_text(strip=True)
            if len(paragraph_text) > 50:  # Tylko dÅ‚uÅ¼sze paragrafy
                if (check_for_keywords(paragraph_text, website_info['keywords']) or 
                    check_for_keywords(paragraph_text, GRANT_KEYWORDS)):
                    found_grants.append({
                        'title': paragraph_text[:150],
                        'url': website_info['url'],
                        'type': 'content',
                        'source': website_info['name']
                    })
        
        # Usuwanie duplikatÃ³w i ograniczenie wynikÃ³w
        unique_grants = []
        seen_titles = set()
        
        for grant in found_grants:
            title_key = grant['title'].lower()[:50]  # Pierwsze 50 znakÃ³w dla porÃ³wnania
            if title_key not in seen_titles:
                seen_titles.add(title_key)
                unique_grants.append(grant)
                if len(unique_grants) >= 3:  # Maksymalnie 3 wyniki na stronÄ™
                    break
        
        return unique_grants
        
    except Exception as e:
        print(f"âŒ BÅ‚Ä…d przy sprawdzaniu {website_info['name']}: {e}")
        return []

def main():
    """GÅ‚Ã³wna funkcja agenta"""
    print(f"ğŸš€ Agent monitorujÄ…cy granty uruchomiony: {datetime.now()}")
    print(f"ğŸ“§ Email bÄ™dzie wysÅ‚any na: {RECIPIENT_EMAIL}")
    
    all_found_grants = []
    
    # Sprawdzanie kaÅ¼dej strony
    for website in WEBSITES_TO_MONITOR:
        print(f"\nğŸ” Sprawdzam: {website['name']}")
        grants = scrape_website(website)
        
        if grants:
            all_found_grants.extend(grants)
            print(f"âœ… Znaleziono {len(grants)} potencjalnych moÅ¼liwoÅ›ci na {website['name']}")
            for grant in grants:
                print(f"   ğŸ“ {grant['title'][:80]}...")
        else:
            print(f"â„¹ï¸ Brak dopasowanych wynikÃ³w na {website['name']}")
        
        # Pauza miÄ™dzy zapytaniami (dobre praktyki)
        time.sleep(3)
    
    # WysyÅ‚anie emaila jeÅ›li znaleziono granty
    if all_found_grants:
        print(f"\nğŸ“Š ÅÄ…cznie znaleziono {len(all_found_grants)} moÅ¼liwoÅ›ci grantowych")
        
        email_content = f"<h3>Znalezione moÅ¼liwoÅ›ci grantowe ({len(all_found_grants)}):</h3><ul>"
        
        for grant in all_found_grants:
            email_content += f"""
            <li>
                <strong>{grant['title']}</strong><br>
                <small>Å¹rÃ³dÅ‚o: {grant['source']} | Typ: {grant['type']}</small><br>
                <a href='{grant['url']}' target='_blank'>ğŸ”— WiÄ™cej informacji</a>
            </li><br>
            """
        
        email_content += "</ul>"
        email_content += f"<p><strong>Sprawdzone strony:</strong></p><ul>"
        
        for website in WEBSITES_TO_MONITOR:
            email_content += f"<li>{website['name']}: <a href='{website['url']}' target='_blank'>{website['url']}</a></li>"
        
        email_content += "</ul>"
        
        subject = f"ğŸ¯ Znaleziono {len(all_found_grants)} nowych moÅ¼liwoÅ›ci grantowych - {datetime.now().strftime('%Y-%m-%d')}"
        
        if send_email(subject, email_content):
            print(f"ğŸ“§ WysÅ‚ano powiadomienie email o {len(all_found_grants)} moÅ¼liwoÅ›ciach grantowych")
        else:
            print("âŒ Nie udaÅ‚o siÄ™ wysÅ‚aÄ‡ emaila")
            
    else:
        print("\nğŸ” Nie znaleziono nowych odpowiednich moÅ¼liwoÅ›ci grantowych")
        print("â„¹ï¸ To moÅ¼e oznaczaÄ‡, Å¼e:")
        print("   - Brak nowych ogÅ‚oszeÅ„")
        print("   - SÅ‚owa kluczowe nie pasujÄ… do dostÄ™pnych treÅ›ci")
        print("   - Strony mogÄ… byÄ‡ tymczasowo niedostÄ™pne")
        
        # Opcjonalnie: wyÅ›lij email informujÄ…cy o braku wynikÃ³w
        summary_email = f"""
        <h3>Raport agenta monitorujÄ…cego granty</h3>
        <p>Agent sprawdziÅ‚ {len(WEBSITES_TO_MONITOR)} stron, ale nie znalazÅ‚ nowych moÅ¼liwoÅ›ci grantowych 
        odpowiadajÄ…cych kryteriom Twojej fundacji.</p>
        
        <p><strong>Sprawdzone strony:</strong></p>
        <ul>
        """
        
        for website in WEBSITES_TO_MONITOR:
            summary_email += f"<li>{website['name']}: <a href='{website['url']}' target='_blank'>{website['url']}</a></li>"
        
        summary_email += """
        </ul>
        <p><small>Agent bÄ™dzie kontynuowaÄ‡ monitorowanie zgodnie z harmonogramem.</small></p>
        """
        
        send_email(f"ğŸ“Š Raport agenta grantowego - brak nowych moÅ¼liwoÅ›ci - {datetime.now().strftime('%Y-%m-%d')}", summary_email)
    
    print(f"\nâœ… Agent zakoÅ„czyÅ‚ pracÄ™: {datetime.now()}")

if __name__ == "__main__":
    main()
